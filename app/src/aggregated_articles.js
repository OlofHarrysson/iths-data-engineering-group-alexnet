// File generated with app/src/generateJsonData.js
export default [
  {
    "unique_id": "a57cdb59-4cac-5ad7-ba41-f437d528ee28",
    "title": "Autonomous innovations in an uncertain world",
    "description": "Jonathan How and his team at the Aerospace Controls Laboratory develop planning algorithms that allow autonomous vehicles to navigate dynamic environments without colliding.",
    "link": "https://news.mit.edu/2023/autonomous-innovations-uncertain-world-jonathan-how-0830",
    "blog_text": "MIT Professor Jonathan How’s research interests span the gamut of autonomous vehicles — from airplanes and spacecraft to unpiloted aerial vehicles (UAVs, or drones) and cars. He is particularly focused on the design and implementation of distributed robust planning algorithms to coordinate multiple autonomous vehicles capable of navigating in dynamic environments.\nFor the past year or so, the Richard Cockburn Maclaurin Professor of Aeronautics and Astronautics and a team of researchers from the Aerospace Controls Laboratory at MIT have been developing a trajectory planning system that allows a fleet of drones to operate in the same airspace without colliding with each other. Put another way, it is a multi-vehicle collision avoidance project, and it has real-world implications around cost savings and efficiency for a variety of industries including agriculture and defense.\nThe test facility for the project is the Kresa Center for Autonomous Systems, an 80-by-40-foot space with 25-foot ceilings, custom designed for MIT’s work with autonomous vehicles — including How’s swarm of UAVs regularly buzzing around the center’s high bay. To avoid collision, each UAV must compute its path-planning trajectory onboard and share it with the rest of the machines using a wireless communication network.\nBut, according to How, one of the key challenges in multi-vehicle work involves communication delays associated with the exchange of information. In this case, to address the issue, How and his researchers embedded a “perception aware” function in their system that allows a vehicle to use the onboard sensors to gather new information about the other vehicles and then alter its own planned trajectory. In testing, their algorithmic fix resulted in a 100 percent success rate, guaranteeing collision-free flights among their group of drones. The next step, says How, is to scale up the algorithms, test in bigger spaces, and eventually fly outside.\nBorn in England, Jonathan How’s fascination with airplanes started at a young age, thanks to ample time spent at airbases with his father, who, for many years, served in the Royal Air Force. However, as How recalls, while other children wanted to be astronauts, his curiosity had more to do with the engineering and mechanics of flight. Years later, as an undergraduate at the University of Toronto, he developed an interest in applied mathematics and multi-vehicle research as it applied to aeronautical and astronautical engineering. He went on to do his graduate and postdoctoral work at MIT, where he contributed to a NASA-funded experiment on advanced control techniques for high-precision pointing and vibration control on spacecraft. And, after working on distributed space telescopes as a junior faculty member at Stanford University, he returned to Cambridge, Massachusetts, to join the faculty at MIT in 2000.\n“One of the key challenges for any autonomous vehicle is how to address what else is in the environment around it,” he says. For autonomous cars that means, among other things, identifying and tracking pedestrians. Which is why How and his team have been collecting real-time data from autonomous cars equipped with sensors designed to track pedestrians, and then they use that information to generate models to understand their behavior — at an intersection, for example — which enables the autonomous vehicle to make short-term predictions and better decisions about how to proceed. “It's a very noisy prediction process, given the uncertainty of the world,” How admits. “The real goal is to improve knowledge. You're never going to get perfect predictions. You're just trying to understand the uncertainty and reduce it as much as you can.”\nOn another project, How is pushing the boundaries of real-time decision-making for aircraft. In these scenarios, the vehicles have to determine where they are located in the environment, what else is around them, and then plan an optimal path forward. Furthermore, to ensure sufficient agility, it is typically necessary to be able to regenerate these solutions at about 10-50 times per second, and as soon as new information from the sensors on the aircraft becomes available. Powerful computers exist, but their cost, size, weight, and power requirements make their deployment on small, agile, aircraft impractical. So how do you quickly perform all the necessary computation — without sacrificing performance — on computers that easily fit on an agile flying vehicle?\nHow’s solution is to employ, on board the aircraft, fast-to-query neural networks that are trained to “imitate” the response of the computationally expensive optimizers. Training is performed during an offline (pre-mission) phase, where he and his researchers run an optimizer repeatedly (thousands of times) that “demonstrates” how to solve a task, and then they embed that knowledge into a neural network. Once the network has been trained, they run it (instead of the optimizer) on the aircraft. In flight, the neural network makes the same decisions that the optimizer would have made, but much faster, significantly reducing the time required to make new decisions. The approach has proven to be successful with UAVs of all sizes, and it can also be used to generate neural networks that are capable of directly processing noisy sensory signals (called end-to-end learning), such as the images from an onboard camera, enabling the aircraft to quickly locate its position or to avoid an obstacle. The exciting innovations here are in the new techniques developed to enable the flying agents to be trained very efficiently – often using only a single task demonstration. One of the important next steps in this project are to ensure that these learned controllers can be certified as being safe.\nOver the years, How has worked closely with companies like Boeing, Lockheed Martin, Northrop Grumman, Ford, and Amazon. He says working with industry helps focus his research on solving real-world problems. “We take industry’s hard problems, condense them down to the core issues, create solutions to specific aspects of the problem, demonstrate those algorithms in our experimental facilities, and then transition them back to the industry. It tends to be a very natural and synergistic feedback loop,” says How.\n",
    "published": "2023-08-30",
    "timestamp": "2023-08-31T13:41:01.204314"
  },
  {
    "unique_id": "32ad1cd0-f288-5c83-b057-7bc699fa4b3e",
    "title": "AI helps robots manipulate objects with their whole bodies",
    "description": "With a new technique, a robot can reason efficiently about moving objects using more than just its fingertips.",
    "link": "https://news.mit.edu/2023/ai-technique-robots-manipulate-objects-whole-bodies-0824",
    "blog_text": "Imagine you want to carry a large, heavy box up a flight of stairs. You might spread your fingers out and lift that box with both hands, then hold it on top of your forearms and balance it against your chest, using your whole body to manipulate the box. \nHumans are generally good at whole-body manipulation, but robots struggle with such tasks. To the robot, each spot where the box could touch any point on the carrier’s fingers, arms, and torso represents a contact event that it must reason about. With billions of potential contact events, planning for this task quickly becomes intractable.\nNow MIT researchers found a way to simplify this process, known as contact-rich manipulation planning. They use an AI technique called smoothing, which summarizes many contact events into a smaller number of decisions, to enable even a simple algorithm to quickly identify an effective manipulation plan for the robot.\nWhile still in its early days, this method could potentially enable factories to use smaller, mobile robots that can manipulate objects with their entire arms or bodies, rather than large robotic arms that can only grasp using fingertips. This may help reduce energy consumption and drive down costs. In addition, this technique could be useful in robots sent on exploration missions to Mars or other solar system bodies, since they could adapt to the environment quickly using only an onboard computer.      \n“Rather than thinking about this as a black-box system, if we can leverage the structure of these kinds of robotic systems using models, there is an opportunity to accelerate the whole procedure of trying to make these decisions and come up with contact-rich plans,” says H.J. Terry Suh, an electrical engineering and computer science (EECS) graduate student and co-lead author of a paper on this technique.\nJoining Suh on the paper are co-lead author Tao Pang PhD ’23, a roboticist at Boston Dynamics AI Institute; Lujie Yang, an EECS graduate student; and senior author Russ Tedrake, the Toyota Professor of EECS, Aeronautics and Astronautics, and Mechanical Engineering, and a member of the Computer Science and Artificial Intelligence Laboratory (CSAIL). The research appears this week in IEEE Transactions on Robotics.\nLearning about learning\nReinforcement learning is a machine-learning technique where an agent, like a robot, learns to complete a task through trial and error with a reward for getting closer to a goal. Researchers say this type of learning takes a black-box approach because the system must learn everything about the world through trial and error.\nIt has been used effectively for contact-rich manipulation planning, where the robot seeks to learn the best way to move an object in a specified manner.\nBut because there may be billions of potential contact points that a robot must reason about when determining how to use its fingers, hands, arms, and body to interact with an object, this trial-and-error approach requires a great deal of computation.\n“Reinforcement learning may need to go through millions of years in simulation time to actually be able to learn a policy,” Suh adds.\nOn the other hand, if researchers specifically design a physics-based model using their knowledge of the system and the task they want the robot to accomplish, that model incorporates structure about this world that makes it more efficient.\nYet physics-based approaches aren’t as effective as reinforcement learning when it comes to contact-rich manipulation planning — Suh and Pang wondered why.\nThey conducted a detailed analysis and found that a technique known as smoothing enables reinforcement learning to perform so well.\nMany of the decisions a robot could make when determining how to manipulate an object aren’t important in the grand scheme of things. For instance, each infinitesimal adjustment of one finger, whether or not it results in contact with the object, doesn’t matter very much.  Smoothing averages away many of those unimportant, intermediate decisions, leaving a few important ones.\nReinforcement learning performs smoothing implicitly by trying many contact points and then computing a weighted average of the results. Drawing on this insight, the MIT researchers designed a simple model that performs a similar type of smoothing, enabling it to focus on core robot-object interactions and predict long-term behavior. They showed that this approach could be just as effective as reinforcement learning at generating complex plans.\n“If you know a bit more about your problem, you can design more efficient algorithms,” Pang says.\nA winning combination\nEven though smoothing greatly simplifies the decisions, searching through the remaining decisions can still be a difficult problem. So, the researchers combined their model with an algorithm that can rapidly and efficiently search through all possible decisions the robot could make.\nWith this combination, the computation time was cut down to about a minute on a standard laptop.\nThey first tested their approach in simulations where robotic hands were given tasks like moving a pen to a desired configuration, opening a door, or picking up a plate. In each instance, their model-based approach achieved the same performance as reinforcement learning, but in a fraction of the time. They saw similar results when they tested their model in hardware on real robotic arms.\n“The same ideas that enable whole-body manipulation also work for planning with dexterous, human-like hands. Previously, most researchers said that reinforcement learning was the only approach that scaled to dexterous hands, but Terry and Tao showed that by taking this key idea of (randomized) smoothing from reinforcement learning, they can make more traditional planning methods work extremely well, too,” Tedrake says.\nHowever, the model they developed relies on a simpler approximation of the real world, so it cannot handle very dynamic motions, such as objects falling. While effective for slower manipulation tasks, their approach cannot create a plan that would enable a robot to toss a can into a trash bin, for instance. In the future, the researchers plan to enhance their technique so it could tackle these highly dynamic motions.\n“If you study your models carefully and really understand the problem you are trying to solve, there are definitely some gains you can achieve. There are benefits to doing things that are beyond the black box,” Suh says.\nThis work is funded, in part, by Amazon, MIT Lincoln Laboratory, the National Science Foundation, and the Ocado Group.\n",
    "published": "2023-08-24",
    "timestamp": "2023-08-31T13:41:01.209454"
  },
  {
    "unique_id": "a20d48f2-53eb-5f8c-96bc-d4397043a884",
    "title": "How to help high schoolers prepare for the rise of artificial intelligence",
    "description": "A one-week summer program aims to foster a deeper understanding of machine-learning approaches in health among curious young minds. ",
    "link": "https://news.mit.edu/2023/how-to-help-high-schoolers-prepare-rise-of-artificial-intelligence-0824",
    "blog_text": "Should artificial intelligence be allowed to make care decisions for patients? Though the future of AI may conjure up doomsday visions of robots and computers intent on rendering human existence superfluous, the MIT Abdul Latif Jameel Clinic for Machine Learning in Health (Jameel Clinic) addressed questions surrounding the use of AI in health through their inaugural summer program focused on educating high school students. \nThe Jameel Clinic Summer Program, which took place July 10-21, accepted a total of 51 students from primarily Boston-area schools, with a commitment to reaching students from diverse backgrounds.  \nThe program, which split students up into two cohorts of 25 students for each week, had core offerings including courses like “Intro to Python,” “Intro to Clinical AI,” and “Intro to Drug Discovery” while also facilitating trips to various local institutions such as the Museum of Science Boston, Massachusetts General Hospital, Janssen Pharmaceuticals, and Amgen. \n“Organizing this boot camp had a personal significance to me. When my family immigrated to Israel, it was tough — my parents and I worked minimum wage jobs to survive,” School of Engineering Distinguished Professor and Jameel Clinic AI faculty lead Regina Barzilay recalls. “Going to university transformed my life. Many of the students in the program have similar backgrounds. I hope that exposing them to exciting science at MIT will open new opportunities for them.” \n“I’m not supposed to be here today,” stated Collin Stultz, the Nina T. and Robert H. Rubin Professor at MIT and Jameel Clinic principal investigator, on becoming both a computer scientist and cardiologist. In his lecture, Stultz spoke of the hardships his parents endured after immigrating to New York from Jamaica. He emphasized that he and his family members had never thought to apply to schools like Harvard University, thinking of it as a school for “people like the Kennedys” until Stultz got the idea to apply from a classmate who was planning to apply.  \n“It is my hope that the interactions between students in the Jameel Clinic Summer Program and MIT faculty will highlight the wealth of opportunities available at the intersection of computer science and medicine,” Stultz says. \nAs a result of a generous gift from Joseph Bates and Kristin Loeffler through their AI for Humanity Foundation, the Jameel Clinic was able to offer the summer program at no cost and reduce the financial barriers for students from under-resourced backgrounds. Bates shared that at the age of 13 he was discovered by a psychology professor at Johns Hopkins University and became the first teenager to enter the university. “I had been doing an adequate, but not good, job in a dangerous Baltimore City public junior high school,” Bates says. “Being at Hopkins was wonderful, socially and intellectually, and it led me to a computer science PhD at Cornell University, then CS professor at Carnegie Mellon University. Someone taking an interest really mattered, and it changed my life.” \nAccording to the National Science Foundation, the U.S. STEM workforce gradually diversified between 2011 and 2021, with increased representation of women and underrepresented students of color. But in the college-educated workforce, a 2021 report showed that just 16 percent of engineers were women and 16 percent of underrepresented students of color — Hispanic, Black, and American Indian or Indigenous Alaskan individuals — were employed in science and engineering occupations with at least a bachelor’s degree. \nAngely Mejia Martinez, a rising junior at Chelsea High School and aspiring doctor, highlighted Jameel Clinic chair and MIT Institute Professor Phillip Sharp’s talk as one of her favorites. Sharp spoke about growing up on a small farm in rural Kentucky before setting off on his career in science, which eventually led to his 1993 Nobel Prize in Physiology and Medicine. “I really got inspired by that because when I was little, many people would say ‘I don’t think you can do this,’ and I was always like ‘I can do this,’” Martinez says. “I think I can achieve anything I set my mind into.” \n“It was very surreal because I didn’t think I’d be here,” Priyani Rawal, a rising junior studying information technology at Essex North Shore Agricultural and Technical School, says. Rawal’s favorite class was Barzilay’s Intro to AI/ML lecture. “I was so amazed by what we were learning ... it made me inspired to go into [the machine learning] field.” \nAdam Nouri, a rising senior at Pioneer Charter School II, signed up for the program after receiving an email from his computer science teacher. Before applying, Nouri had considered enrolling in a summer course for programming at Bunker Hill Community College, an option typically offered at no cost to Pioneer students. However, Nouri quickly realized that free enrollment was only available during the school year and says it would have cost around $800 for him to enroll in the summer. If he hadn’t gotten into the Jameel Clinic Summer Program, Nouri believes he would have continued working at his part-time service job for the rest of the summer while trying to code a game or build a computer with his friends in his free time. “When I got into the [Jameel Clinic Summer Program], I was actually really excited,” Nouri recalls. “Now I feel like I have a clearer path I want to pursue.” \nAs part of their final group project presentations given on the last day of the program, students were assigned AI tools used in clinical settings or drug discovery, like PathAI or AlphaFold2, and asked to explain their assigned tool along with its potential benefits and risks to a target audience of their choice. \n“There is a heavy emphasis placed not only on innovation in science, health care and technology, but also on collaboration across disciplines,” Jay Ananth, a rising junior at Troy High School, says. “During the summer program, I was taught AI and health care not as a high school student, but as a peer — a fellow researcher — who has the ability to innovate and make a change.” \nSerena Hu, a rising junior at Lincoln Sudbury High School, felt less uncertainty about her future after attending the program. “I always wanted to try new things so that I could find something that I love to do, but I can pretty confidently say that I found it here,” Hu says. “They’re not just teaching you the material — they’re also inspiring you.” \nThe Jameel Clinic Summer Program was organized by Ignacio Fuentes, Alex Ouyang, and Marinalva Smith. Maggie Wang, Antonella Catanzaro, Tien Pham, Ciarra Brodie, Rohan Kundargi, Christina Moscat, and the Mass General Brigham team helped to oversee and contribute to the success of the program. Instructors included Pulkit Agrawal, Sharifa Alghowinem, Shrooq Alsenan, Manisha Bahl, Regina Barzilay, Rebecca Boiarsky, Felix Faltings, Florian Fintelmann, Marzyeh Ghassemi, Susan Hockfield, Insoo Hyun, Noah Jones, Ila Kumar, Peter Mikhael, Carles Monterrubio, Rosalind Picard, Tiffany Pereira Portela, Phillip Sharp, Hannes Stärk, Vinith Suriyakumar, Oliver Thiel, Randi Williams, Jeremy Wohlwend, and Rachel Wu.\n",
    "published": "2023-08-24",
    "timestamp": "2023-08-31T13:41:01.206853"
  },
  {
    "unique_id": "a3f439db-fbcb-5c73-879c-413384a07a74",
    "title": "Supporting sustainability, digital health, and the future of work",
    "description": "The MIT and Accenture Convergence Initiative for Industry and Technology selects three new research projects to support. ",
    "link": "https://news.mit.edu/2023/supporting-sustainability-digital-health-future-work-0824",
    "blog_text": "The MIT and Accenture Convergence Initiative for Industry and Technology has selected three new research projects that will receive support from the initiative. The research projects aim to accelerate progress in meeting complex societal needs through new business convergence insights in technology and innovation.\nEstablished in MIT’s School of Engineering and now in its third year, the MIT and Accenture Convergence Initiative is furthering its mission to bring together technological experts from across business and academia to share insights and learn from one another. Recently, Thomas W. Malone, the Patrick J. McGovern (1959) Professor of Management, joined the initiative as its first-ever faculty lead. The research projects relate to three of the initiative’s key focus areas: sustainability, digital health, and the future of work.\n“The solutions these research teams are developing have the potential to have tremendous impact,” says Anantha Chandrakasan, dean of the School of Engineering and the Vannevar Bush Professor of Electrical Engineering and Computer Science. “They embody the initiative’s focus on advancing data-driven research that addresses technology and industry convergence.”\n“The convergence of science and technology driven by advancements in generative AI, digital twins, quantum computing, and other technologies makes this an especially exciting time for Accenture and MIT to be undertaking this joint research,” says Kenneth Munie, senior managing director at Accenture Strategy, Life Sciences. “Our three new research projects focusing on sustainability, digital health, and the future of work have the potential to help guide and shape future innovations that will benefit the way we work and live.”\nThe MIT and Accenture Convergence Initiative charter project researchers are described below.\nAccelerating the journey to net zero with industrial clusters\nJessika Trancik is a professor at the Institute for Data, Systems, and Society (IDSS). Trancik’s research examines the dynamic costs, performance, and environmental impacts of energy systems to inform climate policy and accelerate beneficial and equitable technology innovation. Trancik’s project aims to identify how industrial clusters can enable companies to derive greater value from decarbonization, potentially making companies more willing to invest in the clean energy transition.\nTo meet the ambitious climate goals that have been set by countries around the world, rising greenhouse gas emissions trends must be rapidly reversed. Industrial clusters — geographically co-located or otherwise-aligned groups of companies representing one or more industries — account for a significant portion of greenhouse gas emissions globally. With major energy consumers “clustered” in proximity, industrial clusters provide a potential platform to scale low-carbon solutions by enabling the aggregation of demand and the coordinated investment in physical energy supply infrastructure.\nIn addition to Trancik, the research team working on this project will include Aliza Khurram, a postdoc in IDSS; Micah Ziegler, an IDSS research scientist; Melissa Stark, global energy transition services lead at Accenture; Laura Sanderfer, strategy consulting manager at Accenture; and Maria De Miguel, strategy senior analyst at Accenture.\nEliminating childhood obesity\nAnette \"Peko\" Hosoi is the Neil and Jane Pappalardo Professor of Mechanical Engineering. A common theme in her work is the fundamental study of shape, kinematic, and rheological optimization of biological systems with applications to the emergent field of soft robotics. Her project will use both data from existing studies and synthetic data to create a return-on-investment (ROI) calculator for childhood obesity interventions so that companies can identify earlier returns on their investment beyond reduced health-care costs.\nChildhood obesity is too prevalent to be solved by a single company, industry, drug, application, or program. In addition to the physical and emotional impact on children, society bears a cost through excess health care spending, lost workforce productivity, poor school performance, and increased family trauma. Meaningful solutions require multiple organizations, representing different parts of society, working together with a common understanding of the problem, the economic benefits, and the return on investment. ROI is particularly difficult to defend for any single organization because investment and return can be separated by many years and involve asymmetric investments, returns, and allocation of risk. Hosoi’s project will consider the incentives for a particular entity to invest in programs in order to reduce childhood obesity.\nHosoi will be joined by graduate students Pragya Neupane and Rachael Kha, both of IDSS, as well a team from Accenture that includes Kenneth Munie, senior managing director at Accenture Strategy, Life Sciences; Kaveh Safavi, senior managing director in Accenture Health Industry; and Elizabeth Naik, global health and public service research lead.\nGenerating innovative organizational configurations and algorithms for dealing with the problem of post-pandemic employment\nThomas Malone is the Patrick J. McGovern (1959) Professor of Management at the MIT Sloan School of Management and the founding director of the MIT Center for Collective Intelligence. His research focuses on how new organizations can be designed to take advantage of the possibilities provided by information technology. Malone will be joined in this project by John Horton, the Richard S. Leghorn (1939) Career Development Professor at the MIT Sloan School of Management, whose research focuses on the intersection of labor economics, market design, and information systems. Malone and Horton’s project will look to reshape the future of work with the help of lessons learned in the wake of the pandemic.\nThe Covid-19 pandemic has been a major disrupter of work and employment, and it is not at all obvious how governments, businesses, and other organizations should manage the transition to a desirable state of employment as the pandemic recedes. Using natural language processing algorithms such as GPT-4, this project will look to identify new ways that companies can use AI to better match applicants to necessary jobs, create new types of jobs, assess skill training needed, and identify interventions to help include women and other groups whose employment was disproportionately affected by the pandemic.\nIn addition to Malone and Horton, the research team will include Rob Laubacher, associate director and research scientist at the MIT Center for Collective Intelligence, and Kathleen Kennedy, executive director at the MIT Center for Collective Intelligence and senior director at MIT Horizon. The team will also include Nitu Nivedita, managing director of artificial intelligence at Accenture, and Thomas Hancock, data science senior manager at Accenture.\n",
    "published": "2023-08-24",
    "timestamp": "2023-08-31T13:41:01.208100"
  },
  {
    "unique_id": "15e2d905-a216-56cc-8aa9-803a14bbe2cb",
    "title": "SMART launches research group to advance AI, automation, and the future of work",
    "description": "Mens, Manus and Machina (M3S) will design technology, training programs, and institutions for successful human-machine collaboration.",
    "link": "https://news.mit.edu/2023/smart-launches-m3s-research-group-advance-ai-automation-future-work-0823",
    "blog_text": "The Singapore MIT-Alliance for Research and Technology (SMART), MIT’s research enterprise in Singapore, has launched a new interdisciplinary research group aimed at tackling key social and institutional challenges around the rise of artificial intelligence and other new technologies. The group, known as Mens, Manus and Machina: How AI Empowers People, Institutions and the City in Singapore (M3S), aims to advance knowledge in these fields and foster collaborative research that generates positive impact for society in Singapore and the world.\nSeeking to redefine the boundaries of AI, automation, and robotics through interdisciplinary research, knowledge sharing, and impactful collaborations, SMART M3S endeavors to design inclusive, resilient, and innovative solutions that empower individuals, institutions, and cities. By exploring the intricate relationship between human capabilities, emerging technologies, and societal structures, it is envisioned that SMART M3S will drive scientific, societal, and commercial impact in Singapore and beyond.\nIn line with Singapore’s Smart Nation initiative and its National AI Strategy, the project will embark on an ambitious five-year endeavor supported by a multimillion-dollar grant from the National Research Foundation of Singapore under its Campus for Research Excellence And Technological Enterprise program. \nBringing together a diverse team of 17 professors from MIT and institutions in Singapore, SMART M3S will draw expertise from local researchers from Singapore Management University (SMU), Singapore University of Technology and Design, the National University of Singapore, and the National Robotics Program of Singapore. M3S will be guided by lead principal investigator Jinhua Zhao of MIT, co-lead principal investigator Daniela Rus of MIT, and co-lead principal investigator Archan Misra of SMU.\nRanked No. 1 in the 2023 Smart City Index, Singapore has facilitated the integration of AI, automation, and robotics by strategic use of data analytics, internet-of-things technologies, and smart infrastructure. Amid the rise of AI and machine learning, SMART M3S will contribute to Singapore’s AI ecosystem by focusing on the human-machine relationship, enhancing existing AI initiatives in the city-state.\nInspired by MIT’s motto of “mens et manus,” Latin for “mind and hand,” the name M3S reflects the research group’s ideals to promote AI and machine use for practical application — technologies that are extensions of humans and augment their lives. M3S integrates research on robotics and AI with human capital development, economic growth, and public acceptability — an intersectional approach to the ongoing transformation of how we work and live.\nThis interdisciplinary approach encompasses tackling key issues such as physical and digital interfaces between humans and machines, machine learning fundamentals, and understanding the implications of AI for human and social capital development. Other areas of focus include work on structuring human-machine teams within organizations and the developing dynamics between humans and machines in resource allocation and human labor (as well as machine power) management.\nResearch conducted could significantly advance aspects of soft robotics, brain interfaces, learning algorithms, task allocation, team formation, model compression, sustainable technology, technology acceptability in the workplace, social acceptability of robotics and AI, and more. The impact of AI on human welfare and productivity and how AI technology can advance both areas are central considerations for the work at SMART M3S, as society navigates the transition toward an AI- and machine-enhanced future.\n“As a species, humans have spent eons learning how to work effectively with each other, but at the scale of human history, we are still neophytes to computation and automation,” says Zhao, an MIT professor of urban studies and planning who is also founding director of the MIT Mobility Initiative. “We focus on two questions at M3S: How will we design AI and robotics technologies and train humans to build the skills and habits necessary for success in a robotics-heavy work environment? How will we adapt our social and business institutions to create the incentives and protections necessary to drive innovation and social welfare?”\n“The M3S collaboration between researchers at MIT and in Singapore, through SMART, will break new ground in our understanding of AI’s impact on the future of work,” adds Rus, the Andrew (1956) and Erna Viterbi Professor of Electrical Engineering and Computer Science at MIT and director of the MIT Computer Science and Artificial Intelligence Laboratory. “By harnessing our collective expertise and innovative spirit, we aim to advance the state of the art in AI and turn this technological advancement into an engine for human potential and societal progress.”\n“M3S is distinguished by its ambition to address the key challenges of human-AI synergy holistically, from both a scientific and societal perspective,” notes Misra, vice provost for research and the Lee Kong Chian Professor of Computer Science at SMU who is also co-director of the A*STAR-SMU Joint Lab in Social and Human-Centered Computing. “It will focus not just on the technical breakthroughs that will allow human workers and AI-enabled machines and software to work interactively, but also on the training and governance mechanisms that ensure that individuals and organizations adapt to and thrive in this new future of work. I’m especially excited to collaborate with MIT researchers on this important national priority for Singapore, which aligns perfectly with SMU’s strategic multidisciplinary research priority area of digital transformation.”\nThrough interdisciplinary research, knowledge sharing, and impactful collaborations, SMART M3S will explore the intricate interplay between human capabilities, emerging technologies, and societal structures, paving the way for designing inclusive, resilient, and innovative solutions that empower individuals, institutions, and cities in Singapore. By engaging with Singaporean collaborators, SMART M3S hopes to enhance Singapore’s ability to create forward-looking AI policies, invigorate Singapore’s economic standing within AI, and support local workforce training and mentorship on AI topics. \n“With our latest interdisciplinary research group, SMART M3S, we further our commitment to bringing scientific, social, and commercial impact to Singapore and beyond,” says Eugene A. Fitzgerald, CEO and director of SMART. “The focus on a human-centric approach to AI advancement should contribute towards Singapore being at the forefront of the future of work.”\nSince its inception in Singapore in 2007, SMART has developed innovations that have transformed and are transforming a multitude of fields such as autonomous driving, agriculture, microelectronics, cell therapy, mechanics and microfluidics platforms for biology and medical diagnostics, and antimicrobial resistance.\nSMART was established by MIT in coordination with the National Research Foundation of Singapore in 2007 to undertake cutting-edge research in areas of interest to both Singapore and MIT. SMART currently comprises an Innovation Center and four interdisciplinary research groups: Antimicrobial Resistance, Critical Analytics for Manufacturing Personalized-Medicine, Disruptive and Sustainable Technologies for Agricultural Precision, and M3S.\n",
    "published": "2023-08-23",
    "timestamp": "2023-08-31T13:41:01.210631"
  },
  {
    "unique_id": "a8149e62-2699-53ca-93c0-a3f93c7a14fc",
    "title": "Machine-learning system based on light could yield more powerful, efficient large language models",
    "description": "MIT system demonstrates greater than 100-fold improvement in energy efficiency and a 25-fold improvement in compute density compared with current systems.",
    "link": "https://news.mit.edu/2023/system-could-yield-more-powerful-efficient-llms-0822",
    "blog_text": "ChatGPT has made headlines around the world with its ability to write essays, email, and computer code based on a few prompts from a user. Now an MIT-led team reports a system that could lead to machine-learning programs several orders of magnitude more powerful than the one behind ChatGPT. The system they developed could also use several orders of magnitude less energy than the state-of-the-art supercomputers behind the machine-learning models of today.\nIn the July 17 issue of Nature Photonics, the researchers report the first experimental demonstration of the new system, which performs its computations based on the movement of light, rather than electrons, using hundreds of micron-scale lasers. With the new system, the team reports a greater than 100-fold improvement in energy efficiency and a 25-fold improvement in compute density, a measure of the power of a system, over state-of-the-art digital computers for machine learning. \nToward the future\nIn the paper, the team also cites “substantially several more orders of magnitude for future improvement.” As a result, the authors continue, the technique “opens an avenue to large-scale optoelectronic processors to accelerate machine-learning tasks from data centers to decentralized edge devices.” In other words, cellphones and other small devices could become capable of running programs that can currently only be computed at large data centers.\nFurther, because the components of the system can be created using fabrication processes already in use today, “we expect that it could be scaled for commercial use in a few years. For example, the laser arrays involved are widely used in cell-phone face ID and data communication,” says Zaijun Chen, first author, who conducted the work while a postdoc at MIT in the Research Laboratory of Electronics (RLE) and is now an assistant professor at the University of Southern California.\nSays Dirk Englund, an associate professor in MIT’s Department of Electrical Engineering and Computer Science and leader of the work, “ChatGPT is limited in its size by the power of today’s supercomputers. It’s just not economically viable to train models that are much bigger. Our new technology could make it possible to leapfrog to machine-learning models that otherwise would not be reachable in the near future.”\nHe continues, “We don’t know what capabilities the next-generation ChatGPT will have if it is 100 times more powerful, but that’s the regime of discovery that this kind of technology can allow.” Englund is also leader of MIT’s Quantum Photonics Laboratory and is affiliated with the RLE and the Materials Research Laboratory.\nA drumbeat of progress\nThe current work is the latest achievement in a drumbeat of progress over the last few years by Englund and many of the same colleagues. For example, in 2019 an Englund team reported the theoretical work that led to the current demonstration. The first author of that paper, Ryan Hamerly, now of RLE and NTT Research Inc., is also an author of the current paper.\nAdditional coauthors of the current Nature Photonics paper are Alexander Sludds, Ronald Davis, Ian Christen, Liane Bernstein, and Lamia Ateshian, all of RLE; and Tobias Heuser, Niels Heermeier, James A. Lott, and Stephan Reitzensttein of Technische Universitat Berlin.\nDeep neural networks (DNNs) like the one behind ChatGPT are based on huge machine-learning models that simulate how the brain processes information. However, the digital technologies behind today’s DNNs are reaching their limits even as the field of machine learning is growing. Further, they require huge amounts of energy and are largely confined to large data centers. That is motivating the development of new computing paradigms.\nUsing light rather than electrons to run DNN computations has the potential to break through the current bottlenecks. Computations using optics, for example, have the potential to use far less energy than those based on electronics. Further, with optics, “you can have much larger bandwidths,” or compute densities, says Chen. Light can transfer much more information over a much smaller area.\nBut current optical neural networks (ONNs) have significant challenges. For example, they use a great deal of energy because they are inefficient at converting incoming data based on electrical energy into light. Further, the components involved are bulky and take up significant space. And while ONNs are quite good at linear calculations like adding, they are not great at nonlinear calculations like multiplication and “if” statements.\nIn the current work the researchers introduce a compact architecture that, for the first time, solves all of these challenges and two more simultaneously. That architecture is based on state-of-the-art arrays of vertical surface-emitting lasers (VCSELs), a relatively new technology used in applications including lidar remote sensing and laser printing. The particular VCELs reported in the Nature Photonics paper were developed by the Reitzenstein group at Technische Universitat Berlin. “This was a collaborative project that would not have been possible without them,” Hamerly says.\nLogan Wright, an assistant professor at Yale University who was not involved in the current research, comments, “The work by Zaijun Chen et al. is inspiring, encouraging me and likely many other researchers in this area that systems based on modulated VCSEL arrays could be a viable route to large-scale, high-speed optical neural networks. Of course, the state of the art here is still far from the scale and cost that would be necessary for practically useful devices, but I am optimistic about what can be realized in the next few years, especially given the potential these systems have to accelerate the very large-scale, very expensive AI systems like those used in popular textual ‘GPT’ systems like ChatGPT.”\nChen, Hamerly, and Englund have filed for a patent on the work, which was sponsored by the U.S. Army Research Office, NTT Research, the U.S. National Defense Science and Engineering Graduate Fellowship Program, the U.S. National Science Foundation, the Natural Sciences and Engineering Research Council of Canada, and the Volkswagen Foundation.\n",
    "published": "2023-08-22",
    "timestamp": "2023-08-31T13:41:01.211646"
  },
  {
    "unique_id": "32627b31-f634-55bf-88a9-f7dd8dcf9d21",
    "title": "Artificial intelligence for augmentation and productivity",
    "description": "The MIT Schwarzman College of Computing awards seed grants to seven interdisciplinary projects exploring AI-augmented management.",
    "link": "https://news.mit.edu/2023/artificial-intelligence-augmentation-and-productivity-0818",
    "blog_text": "The MIT Stephen A. Schwarzman College of Computing has awarded seed grants to seven projects that are exploring how artificial intelligence and human-computer interaction can be leveraged to enhance modern work spaces to achieve better management and higher productivity.\nFunded by Andrew W. Houston ’05 and Dropbox Inc., the projects are intended to be interdisciplinary and bring together researchers from computing, social sciences, and management.\nThe seed grants can enable the project teams to conduct research that leads to bigger endeavors in this rapidly evolving area, as well as build community around questions related to AI-augmented management.\nThe seven selected projects and research leads include:\n“LLMex: Implementing Vannevar Bush’s Vision of the Memex Using Large Language Models,” led by Pattie Maes of the Media Lab and David Karger of the Department of Electrical Engineering and Computer Science (EECS) and the Computer Science and Artificial Intelligence Laboratory (CSAIL). Inspired by Vannevar Bush’s Memex, this project proposes to design, implement, and test the concept of memory prosthetics using large language models (LLMs). The AI-based system will intelligently help an individual keep track of vast amounts of information, accelerate productivity, and reduce errors by automatically recording their work actions and meetings, supporting retrieval based on metadata and vague descriptions, and suggesting relevant, personalized information proactively based on the user’s current focus and context.\n“Using AI Agents to Simulate Social Scenarios,” led by John Horton of the MIT Sloan School of Management and Jacob Andreas of EECS and CSAIL. This project imagines the ability to easily simulate policies, organizational arrangements, and communication tools with AI agents before implementation. Tapping into the capabilities of modern LLMs to serve as a computational model of humans makes this vision of social simulation more realistic, and potentially more predictive.\n“Human Expertise in the Age of AI: Can We Have Our Cake and Eat it Too?” led by Manish Raghavan of MIT Sloan and EECS, and Devavrat Shah of EECS and the Laboratory for Information and Decision Systems. Progress in machine learning, AI, and in algorithmic decision aids has raised the prospect that algorithms may complement human decision-making in a wide variety of settings. Rather than replacing human professionals, this project sees a future where AI and algorithmic decision aids play a role that is complementary to human expertise.\n“Implementing Generative AI in U.S. Hospitals,” led by Julie Shah of the Department of Aeronautics and Astronautics and CSAIL, Retsef Levi of MIT Sloan and the Operations Research Center, Kate Kellog of MIT Sloan, and Ben Armstrong of the Industrial Performance Center. In recent years, studies have linked a rise in burnout from doctors and nurses in the United States with increased administrative burdens associated with electronic health records and other technologies. This project aims to develop a holistic framework to study how generative AI technologies can both increase productivity for organizations and improve job quality for workers in health care settings.\n“Generative AI Augmented Software Tools to Democratize Programming,” led by Harold Abelson of EECS and CSAIL, Cynthia Breazeal of the Media Lab, and Eric Klopfer of the Comparative Media Studies/Writing. Progress in generative AI over the past year is fomenting an upheaval in assumptions about future careers in software and deprecating the role of coding. This project will stimulate a similar transformation in computing education for those who have no prior technical training by creating a software tool that could eliminate much of the need for learners to deal with code when creating applications.\n“Acquiring Expertise and Societal Productivity in a World of Artificial Intelligence,” led by David Atkin and Martin Beraja of the Department of Economics, and Danielle Li of MIT Sloan. Generative AI is thought to augment the capabilities of workers performing cognitive tasks. This project seeks to better understand how the arrival of AI technologies may impact skill acquisition and productivity, and to explore complementary policy interventions that will allow society to maximize the gains from such technologies.\n“AI Augmented Onboarding and Support,” led by Tim Kraska of EECS and CSAIL, and Christoph Paus of the Department of Physics and the Laboratory for Nuclear Science. While LLMs have made enormous leaps forward in recent years and are poised to fundamentally change the way students and professionals learn about new tools and systems, there is often a steep learning curve which people have to climb in order to make full use of the resource. To help mitigate the issue, this project proposes the development of new LLM-powered onboarding and support systems that will positively impact the way support teams operate and improve the user experience.\n",
    "published": "2023-08-18",
    "timestamp": "2023-08-31T13:41:01.213078"
  },
  {
    "unique_id": "32627b31-f634-55bf-88a9-f7dd8dcf9d21",
    "title": "Artificial intelligence for augmentation and productivity",
    "description": "The MIT Schwarzman College of Computing awards seed grants to seven interdisciplinary projects exploring AI-augmented management.",
    "link": "https://news.mit.edu/2023/artificial-intelligence-augmentation-and-productivity-0818",
    "blog_text": "The MIT Stephen A. Schwarzman College of Computing has awarded seed grants to seven projects that are exploring how artificial intelligence and human-computer interaction can be leveraged to enhance modern work spaces to achieve better management and higher productivity.\nFunded by Andrew W. Houston ’05 and Dropbox Inc., the projects are intended to be interdisciplinary and bring together researchers from computing, social sciences, and management.\nThe seed grants can enable the project teams to conduct research that leads to bigger endeavors in this rapidly evolving area, as well as build community around questions related to AI-augmented management.\nThe seven selected projects and research leads include:\n“LLMex: Implementing Vannevar Bush’s Vision of the Memex Using Large Language Models,” led by Patti Maes of the Media Lab and David Karger of the Department of Electrical Engineering and Computer Science (EECS) and the Computer Science and Artificial Intelligence Laboratory (CSAIL). Inspired by Vannevar Bush’s Memex, this project proposes to design, implement, and test the concept of memory prosthetics using large language models (LLMs). The AI-based system will intelligently help an individual keep track of vast amounts of information, accelerate productivity, and reduce errors by automatically recording their work actions and meetings, supporting retrieval based on metadata and vague descriptions, and suggesting relevant, personalized information proactively based on the user’s current focus and context.\n“Using AI Agents to Simulate Social Scenarios,” led by John Horton of the MIT Sloan School of Management and Jacob Andreas of EECS and CSAIL. This project imagines the ability to easily simulate policies, organizational arrangements, and communication tools with AI agents before implementation. Tapping into the capabilities of modern LLMs to serve as a computational model of humans makes this vision of social simulation more realistic, and potentially more predictive.\n“Human Expertise in the Age of AI: Can We Have Our Cake and Eat it Too?” led by Manish Raghavan of MIT Sloan and EECS, and Devavrat Shah of EECS and the Laboratory for Information and Decision Systems. Progress in machine learning, AI, and in algorithmic decision aids has raised the prospect that algorithms may complement human decision-making in a wide variety of settings. Rather than replacing human professionals, this project sees a future where AI and algorithmic decision aids play a role that is complementary to human expertise.\n“Implementing Generative AI in U.S. Hospitals,” led by Julie Shah of the Department of Aeronautics and Astronautics and CSAIL, Retsef Levi of MIT Sloan and the Operations Research Center, Kate Kellog of MIT Sloan, and Ben Armstrong of the Industrial Performance Center. In recent years, studies have linked a rise in burnout from doctors and nurses in the United States with increased administrative burdens associated with electronic health records and other technologies. This project aims to develop a holistic framework to study how generative AI technologies can both increase productivity for organizations and improve job quality for workers in health care settings.\n“Generative AI Augmented Software Tools to Democratize Programming,” led by Harold Abelson of EECS and CSAIL, Cynthia Breazeal of the Media Lab, and Eric Klopfer of the Comparative Media Studies/Writing. Progress in generative AI over the past year is fomenting an upheaval in assumptions about future careers in software and deprecating the role of coding. This project will stimulate a similar transformation in computing education for those who have no prior technical training by creating a software tool that could eliminate much of the need for learners to deal with code when creating applications.\n“Acquiring Expertise and Societal Productivity in a World of Artificial Intelligence,” led by David Atkin and Martin Beraja of the Department of Economics, and Danielle Li of MIT Sloan. Generative AI is thought to augment the capabilities of workers performing cognitive tasks. This project seeks to better understand how the arrival of AI technologies may impact skill acquisition and productivity, and to explore complementary policy interventions that will allow society to maximize the gains from such technologies.\n“AI Augmented Onboarding and Support,” led by Tim Kraska of EECS and CSAIL, and Christoph Paus of the Department of Physics and the Laboratory for Nuclear Science. While LLMs have made enormous leaps forward in recent years and are poised to fundamentally change the way students and professionals learn about new tools and systems, there is often a steep learning curve which people have to climb in order to make full use of the resource. To help mitigate the issue, this project proposes the development of new LLM-powered onboarding and support systems that will positively impact the way support teams operate and improve the user experience.\n",
    "published": "2023-08-18",
    "timestamp": "2023-08-24T13:21:21.394490"
  },
  {
    "unique_id": "326387a7-f4f0-5de1-bee6-2d87b46e0224",
    "title": "How machine learning models can amplify inequities in medical diagnosis and treatment",
    "description": "MIT researchers investigate the causes of health-care disparities among underrepresented groups.<br />",
    "link": "https://news.mit.edu/2023/how-machine-learning-models-can-amplify-inequities-medical-diagnosis-treatment-0817",
    "blog_text": "Prior to receiving a PhD in computer science from MIT in 2017, Marzyeh Ghassemi had already begun to wonder whether the use of AI techniques might enhance the biases that already existed in health care. She was one of the early researchers to take up this issue, and she’s been exploring it ever since. In a new paper, Ghassemi, now an assistant professor in MIT’s Department of Electrical Science and Engineering (EECS), and three collaborators based at the Computer Science and Artificial Intelligence Laboratory, have probed the roots of the disparities that can arise in machine learning, often causing models that perform well overall to falter when it comes to subgroups for which relatively few data have been collected and utilized in the training process. The paper — written by two MIT PhD students, Yuzhe Yang and Haoran Zhang, EECS computer scientist Dina Katabi (the Thuan and Nicole Pham Professor), and Ghassemi — was presented last month at the 40th International Conference on Machine Learning in Honolulu, Hawaii.\nIn their analysis, the researchers focused on \"subpopulation shifts\" — differences in the way machine learning models perform for one subgroup as compared to another. “We want the models to be fair and work equally well for all groups, but instead we consistently observe the presence of shifts among different groups that can lead to inferior medical diagnosis and treatment,” says Yang, who along with Zhang are the two lead authors on the paper. The main point of their inquiry is to determine the kinds of subpopulation shifts that can occur and to uncover the mechanisms behind them so that, ultimately, more equitable models can be developed.\nThe new paper “significantly advances our understanding” of the subpopulation shift phenomenon, claims Stanford University computer scientist Sanmi Koyejo. “This research contributes valuable insights for future advancements in machine learning models' performance on underrepresented subgroups.”\nCamels and cattle\nThe MIT group has identified four principal types of shifts — spurious correlations, attribute imbalance, class imbalance, and attribute generalization — which, according to Yang, “have never been put together into a coherent and unified framework. We’ve come up with a single equation that shows you where biases can come from.”\nBiases can, in fact, stem from what the researchers call the class, or from the attribute, or both. To pick a simple example, suppose the task assigned to the machine learning model is to sort images of objects — animals in this case — into two classes: cows and camels. Attributes are descriptors that don’t specifically relate to the class itself. It might turn out, for instance, that all the images used in the analysis show cows standing on grass and camels on sand — grass and sand serving as the attributes here. Given the data available to it, the machine could reach an erroneous conclusion — namely that cows can only be found on grass, not on sand, with the opposite being true for camels. Such a finding would be incorrect, however, giving rise to a spurious correlation, which, Yang explains, is a “special case” among subpopulation shifts — “one in which you have a bias in both the class and the attribute.”\nIn a medical setting, one could rely on machine learning models to determine whether a person has pneumonia or not based on an examination of X-ray images. There would be two classes in this situation, one consisting of people who have the lung ailment, another for those who are infection-free. A relatively straightforward case would involve just two attributes: the people getting X-rayed are either female or male. If, in this particular dataset, there were 100 males diagnosed with pneumonia for every one female diagnosed with pneumonia, that could lead to an attribute imbalance, and the model would likely do a better job of correctly detecting pneumonia for a man than for a woman. Similarly, having 1,000 times more healthy (pneumonia-free) subjects than sick ones would lead to a class imbalance, with the model biased toward healthy cases. Attribute generalization is the last shift highlighted in the new study. If your sample contained 100 male patients with pneumonia and zero female subjects with the same illness, you still would like the model to be able to generalize and make predictions about female subjects even though there are no samples in the training data for females with pneumonia.\nThe team then took 20 advanced algorithms, designed to carry out classification tasks, and tested them on a dozen datasets to see how they performed across different population groups. They reached some unexpected conclusions: By improving the “classifier,” which is the last layer of the neural network, they were able to reduce the occurrence of spurious correlations and class imbalance, but the other shifts were unaffected. Improvements to the “encoder,” one of the uppermost layers in the neural network, could reduce the problem of attribute imbalance. “However, no matter what we did to the encoder or classifier, we did not see any improvements in terms of attribute generalization,” Yang says, “and we don’t yet know how to address that.”\nPrecisely accurate\nThere is also the question of assessing how well your model actually works in terms of evenhandedness among different population groups. The metric normally used, called worst-group accuracy or WGA, is based on the assumption that if you can improve the accuracy — of, say, medical diagnosis — for the group that has the worst model performance, you would have improved the model as a whole. “The WGA is considered the gold standard in subpopulation evaluation,” the authors contend, but they made a surprising discovery: boosting worst-group accuracy results in a decrease in what they call “worst-case precision.” In medical decision-making of all sorts, one needs both accuracy — which speaks to the validity of the findings — and precision, which relates to the reliability of the methodology. “Precision and accuracy are both very important metrics in classification tasks, and that is especially true in medical diagnostics,” Yang explains. “You should never trade precision for accuracy. You always need to balance the two.”\nThe MIT scientists are putting their theories into practice. In a study they're conducting with a medical center, they’re looking at public datasets for tens of thousands of patients and hundreds of thousands of chest X-rays, trying to see whether it’s possible for machine learning models to work in an unbiased manner for all populations. That’s still far from the case, even though more awareness has been drawn to this problem, Yang says. “We are finding many disparities across different ages, gender, ethnicity, and intersectional groups.”\nHe and his colleagues agree on the eventual goal, which is to achieve fairness in health care among all populations. But before we can reach that point, they maintain, we still need a better understanding of the sources of unfairness and how they permeate our current system. Reforming the system as a whole will not be easy, they acknowledge. In fact, the title of the paper they introduced at the Honolulu conference, “Change is Hard,” gives some indications as to the challenges that they and like-minded researchers face.\nThis research is funded by the MIT-IBM Watson AI Lab.\n",
    "published": "2023-08-17",
    "timestamp": "2023-08-28T13:36:51.688369"
  },
  {
    "unique_id": "98f0a8ee-00b5-5d7e-be05-d1581c2b5860",
    "title": "How machine-learning models can amplify inequities in medical diagnosis and treatment",
    "description": "MIT researchers investigate the causes of health care disparities among underrepresented groups.<br />",
    "link": "https://news.mit.edu/2023/how-machine-learning-models-can-amplify-inequities-medical-diagnosis-treatment-0817",
    "blog_text": "Prior to receiving a PhD in computer science from MIT in 2017, Marzyeh Ghassemi had already begun to wonder whether the use of AI techniques might enhance the biases that already existed in health care. She was one of the early researchers to take up this issue, and she’s been exploring it ever since. In a new paper, Ghassemi, now an assistant professor in MIT’s Department of Electrical Science and Engineering (EECS), and three collaborators based at the Computer Science and Artificial Intelligence Laboratory, have probed the roots of the disparities that can arise in machine learning, often causing models that perform well overall to falter when it comes to subgroups for which relatively few data have been collected and utilized in the training process. The paper — written by two MIT PhD students, Yuzhe Yang and Haoran Zhang, EECS computer scientist Dina Katabi (the Thuan and Nicole Pham Professor), and Ghassemi — was presented last month at the 40th International Conference on Machine Learning in Honolulu, Hawaii.\nIn their analysis, the researchers focused on \"subpopulation shifts\" — differences in the way machine learning models perform for one subgroup as compared to another. “We want the models to be fair and work equally well for all groups, but instead we consistently observe the presence of shifts among different groups that can lead to inferior medical diagnosis and treatment,” says Yang, who along with Zhang are the two lead authors on the paper. The main point of their inquiry is to determine the kinds of subpopulation shifts that can occur and to uncover the mechanisms behind them so that, ultimately, more equitable models can be developed.\nThe new paper “significantly advances our understanding” of the subpopulation shift phenomenon, claims Stanford University computer scientist Sanmi Koyejo. “This research contributes valuable insights for future advancements in machine learning models' performance on underrepresented subgroups.”\nCamels and cattle\nThe MIT group has identified four principal types of shifts — spurious correlations, attribute imbalance, class imbalance, and attribute generalization — which, according to Yang, “have never been put together into a coherent and unified framework. We’ve come up with a single equation that shows you where biases can come from.”\nBiases can, in fact, stem from what the researchers call the class, or from the attribute, or both. To pick a simple example, suppose the task assigned to the machine learning model is to sort images of objects — animals in this case — into two classes: cows and camels. Attributes are descriptors that don’t specifically relate to the class itself. It might turn out, for instance, that all the images used in the analysis show cows standing on grass and camels on sand — grass and sand serving as the attributes here. Given the data available to it, the machine could reach an erroneous conclusion — namely that cows can only be found on grass, not on sand, with the opposite being true for camels. Such a finding would be incorrect, however, giving rise to a spurious correlation, which, Yang explains, is a “special case” among subpopulation shifts — “one in which you have a bias in both the class and the attribute.”\nIn a medical setting, one could rely on machine learning models to determine whether a person has pneumonia or not based on an examination of X-ray images. There would be two classes in this situation, one consisting of people who have the lung ailment, another for those who are infection-free. A relatively straightforward case would involve just two attributes: the people getting X-rayed are either female or male. If, in this particular dataset, there were 100 males diagnosed with pneumonia for every one female diagnosed with pneumonia, that could lead to an attribute imbalance, and the model would likely do a better job of correctly detecting pneumonia for a man than for a woman. Similarly, having 1,000 times more healthy (pneumonia-free) subjects than sick ones would lead to a class imbalance, with the model biased toward healthy cases. Attribute generalization is the last shift highlighted in the new study. If your sample contained 100 male patients with pneumonia and zero female subjects with the same illness, you still would like the model to be able to generalize and make predictions about female subjects even though there are no samples in the training data for females with pneumonia.\nThe team then took 20 advanced algorithms, designed to carry out classification tasks, and tested them on a dozen datasets to see how they performed across different population groups. They reached some unexpected conclusions: By improving the “classifier,” which is the last layer of the neural network, they were able to reduce the occurrence of spurious correlations and class imbalance, but the other shifts were unaffected. Improvements to the “encoder,” one of the uppermost layers in the neural network, could reduce the problem of attribute imbalance. “However, no matter what we did to the encoder or classifier, we did not see any improvements in terms of attribute generalization,” Yang says, “and we don’t yet know how to address that.”\nPrecisely accurate\nThere is also the question of assessing how well your model actually works in terms of evenhandedness among different population groups. The metric normally used, called worst-group accuracy or WGA, is based on the assumption that if you can improve the accuracy — of, say, medical diagnosis — for the group that has the worst model performance, you would have improved the model as a whole. “The WGA is considered the gold standard in subpopulation evaluation,” the authors contend, but they made a surprising discovery: boosting worst-group accuracy results in a decrease in what they call “worst-case precision.” In medical decision-making of all sorts, one needs both accuracy — which speaks to the validity of the findings — and precision, which relates to the reliability of the methodology. “Precision and accuracy are both very important metrics in classification tasks, and that is especially true in medical diagnostics,” Yang explains. “You should never trade precision for accuracy. You always need to balance the two.”\nThe MIT scientists are putting their theories into practice. In a study they're conducting with a medical center, they’re looking at public datasets for tens of thousands of patients and hundreds of thousands of chest X-rays, trying to see whether it’s possible for machine learning models to work in an unbiased manner for all populations. That’s still far from the case, even though more awareness has been drawn to this problem, Yang says. “We are finding many disparities across different ages, gender, ethnicity, and intersectional groups.”\nHe and his colleagues agree on the eventual goal, which is to achieve fairness in health care among all populations. But before we can reach that point, they maintain, we still need a better understanding of the sources of unfairness and how they permeate our current system. Reforming the system as a whole will not be easy, they acknowledge. In fact, the title of the paper they introduced at the Honolulu conference, “Change is Hard,” gives some indications as to the challenges that they and like-minded researchers face.\nThis research is funded by the MIT-IBM Watson AI Lab.\n",
    "published": "2023-08-17",
    "timestamp": "2023-08-31T13:41:01.214817"
  },
  {
    "unique_id": "326387a7-f4f0-5de1-bee6-2d87b46e0224",
    "title": "How machine learning models can amplify inequities in medical diagnosis and treatment",
    "description": "MIT researchers investigate the causes of health-care disparities among underrepresented groups.<br />",
    "link": "https://news.mit.edu/2023/how-machine-learning-models-can-amplify-inequities-medical-diagnosis-treatment-0817",
    "blog_text": "Prior to receiving a PhD in computer science from MIT in 2017, Marzyeh Ghassemi had already begun to wonder whether the use of AI techniques might enhance the biases that already existed in health care. She was one of the early researchers to take up this issue, and she’s been exploring it ever since. In a new paper, Ghassemi, now an assistant professor in MIT’s Department of Electrical Science and Engineering (EECS), and three collaborators based at the Computer Science and Artificial Intelligence Laboratory, have probed the roots of the disparities that can arise in machine learning, often causing models that perform well overall to falter when it comes to subgroups for which relatively few data have been collected and utilized in the training process. The paper — written by two MIT PhD students, Yuzhe Yang and Haoran Zhang, EECS computer scientist Dina Katabi (the Thuan and Nicole Pham Professor), and Ghassemi — was presented last month at the 40th International Conference on Machine Learning in Honolulu, Hawaii.\nIn their analysis, the researchers focused on \"subpopulation shifts\" — differences in the way machine learning models perform for one subgroup as compared to another. “We want the models to be fair and work equally well for all groups, but instead we consistently observe the presence of shifts among different groups that can lead to inferior medical diagnosis and treatment,” says Yang, who along with Zhang are the two lead authors on the paper. The main point of their inquiry is to determine the kinds of subpopulation shifts that can occur and to uncover the mechanisms behind them so that, ultimately, more equitable models can be developed.\nThe new paper “significantly advances our understanding” of the subpopulation shift phenomenon, claims Stanford University computer scientist Sanmi Koyejo. “This research contributes valuable insights for future advancements in machine learning models' performance on underrepresented subgroups.”\nCamels and cattle\nThe MIT group has identified four principal types of shifts — spurious correlations, attribute imbalance, class imbalance, and attribute generalization — which, according to Yang, “have never been put together into a coherent and unified framework. We’ve come up with a single equation that shows you where biases can come from.”\nBiases can, in fact, stem from what the researchers call the class, or from the attribute, or both. To pick a simple example, suppose the task assigned to the machine learning model is to sort images of objects — animals in this case — into two classes: cows and camels. Attributes are descriptors that don’t specifically relate to the class itself. It might turn out, for instance, that all the images used in the analysis show cows standing on grass and camels on sand — grass and sand serving as the attributes here. Given the data available to it, the machine could reach an erroneous conclusion — namely that cows can only be found on grass, not on sand, with the opposite being true for camels. Such a finding would be incorrect, however, giving rise to a spurious correlation, which, Yang explains, is a “special case” among subpopulation shifts — “one in which you have a bias in both the class and the attribute.”\nIn a medical setting, one could rely on machine learning models to determine whether a person has pneumonia or not based on an examination of X-ray images. There would be two classes in this situation, one consisting of people who have the lung ailment, another for those who are infection-free. A relatively straightforward case would involve just two attributes: the people getting X-rayed are either female or male. If, in this particular dataset, there were 100 males diagnosed with pneumonia for every one female diagnosed with pneumonia, that could lead to an attribute imbalance, and the model would likely do a better job of correctly detecting pneumonia for a man than for a woman. Similarly, having 1,000 times more healthy (pneumonia-free) subjects than sick ones would lead to a class imbalance, with the model biased toward healthy cases. Attribute generalization is the last shift highlighted in the new study. If your sample contained 100 male patients with pneumonia and zero female subjects with the same illness, you still would like the model to be able to generalize and make predictions about female subjects even though there are no samples in the training data for females with pneumonia.\nThe team then took 20 advanced algorithms, designed to carry out classification tasks, and tested them on a dozen datasets to see how they performed across different population groups. They reached some unexpected conclusions: By improving the “classifier,” which is the last layer of the neural network, they were able to reduce the occurrence of spurious correlations and class imbalance, but the other shifts were unaffected. Improvements to the “encoder,” one of the uppermost layers in the neural network, could reduce the problem of attribute imbalance. “However, no matter what we did to the encoder or classifier, we did not see any improvements in terms of attribute generalization,” Yang says, “and we don’t yet know how to address that.”\nPrecisely accurate\nThere is also the question of assessing how well your model actually works in terms of evenhandedness among different population groups. The metric normally used, called worst-group accuracy or WGA, is based on the assumption that if you can improve the accuracy — of, say, medical diagnosis — for the group that has the worst model performance, you would have improved the model as a whole. “The WGA is considered the gold standard in subpopulation evaluation,” the authors contend, but they made a surprising discovery: boosting worst-group accuracy results in a decrease in what they call “worst-case precision.” In medical decision-making of all sorts, one needs both accuracy — which speaks to the validity of the findings — and precision, which relates to the reliability of the methodology. “Precision and accuracy are both very important metrics in classification tasks, and that is especially true in medical diagnostics,” Yang explains. “You should never trade precision for accuracy. You always need to balance the two.”\nThe MIT scientists are putting their theories into practice. In a study they're conducting with a medical center, they’re looking at public datasets for tens of thousands of patients and hundreds of thousands of chest X-rays, trying to see whether it’s possible for machine learning models to work in an unbiased manner for all populations. That’s still far from the case, even though more awareness has been drawn to this problem, Yang says. “We are finding many disparities across different ages, gender, ethnicity, and intersectional groups.”\nHe and his colleagues agree on the eventual goal, which is to achieve fairness in health care among all populations. But before we can reach that point, they maintain, we still need a better understanding of the sources of unfairness and how they permeate our current system. Reforming the system as a whole will not be easy, they acknowledge. In fact, the title of the paper they introduced at the Honolulu conference, “Change is Hard,” gives some indications as to the challenges that they and like-minded researchers face.\nThis research is funded by the MIT-IBM Watson AI Lab.\n",
    "published": "2023-08-17",
    "timestamp": "2023-08-24T13:21:21.397700"
  },
  {
    "unique_id": "f7031fbd-8590-5c68-afd9-01cb58e953c0",
    "title": "MIT researchers combine deep learning and physics to fix motion-corrupted MRI scans",
    "description": "The challenge involves more than just a blurry JPEG. Fixing motion artifacts in medical imaging requires a more sophisticated approach.",
    "link": "https://news.mit.edu/2023/mit-researchers-combine-deep-learning-physics-fix-motion-corrupted-MRI-scans-0817",
    "blog_text": "Compared to other imaging modalities like X-rays or CT scans, MRI scans provide high-quality soft tissue contrast. Unfortunately, MRI is highly sensitive to motion, with even the smallest of movements resulting in image artifacts. These artifacts put patients at risk of misdiagnoses or inappropriate treatment when critical details are obscured from the physician. But researchers at MIT may have developed a deep learning model capable of motion correction in brain MRI.\n“Motion is a common problem in MRI,” explains Nalini Singh, an Abdul Latif Jameel Clinic for Machine Learning in Health (Jameel Clinic)-affiliated PhD student in the Harvard-MIT Program in Health Sciences and Technology (HST) and lead author of the paper. “It’s a pretty slow imaging modality.”\nMRI sessions can take anywhere from a few minutes to an hour, depending on the type of images required. Even during the shortest scans, small movements can have dramatic effects on the resulting image. Unlike camera imaging, where motion typically manifests as a localized blur, motion in MRI often results in artifacts that can corrupt the whole image. Patients may be anesthetized or requested to limit deep breathing in order to minimize motion. However, these measures often cannot be taken in populations particularly susceptible to motion, including children and patients with psychiatric disorders. \nThe paper, titled “Data Consistent Deep Rigid MRI Motion Correction,” was recently awarded best oral presentation at the Medical Imaging with Deep Learning conference (MIDL) in Nashville, Tennessee. The method computationally constructs a motion-free image from motion-corrupted data without changing anything about the scanning procedure. “Our aim was to combine physics-based modeling and deep learning to get the best of both worlds,” Singh says.\nThe importance of this combined approach lies within ensuring consistency between the image output and the actual measurements of what is being depicted, otherwise the model creates “hallucinations” — images that appear realistic, but are physically and spatially inaccurate, potentially worsening outcomes when it comes to diagnoses.\nProcuring an MRI free of motion artifacts, particularly from patients with neurological disorders that cause involuntary movement, such as Alzheimer’s or Parkinson’s disease, would benefit more than just patient outcomes. A study from the University of Washington Department of Radiology estimated that motion affects 15 percent of brain MRIs. Motion in all types of MRI that leads to repeated scans or imaging sessions to obtain images with sufficient quality for diagnosis results in approximately $115,000 in hospital expenditures per scanner on an annual basis.\nAccording to Singh, future work could explore more sophisticated types of head motion as well as motion in other body parts. For instance, fetal MRI suffers from rapid, unpredictable motion that cannot be modeled only by simple translations and rotations. \n“This line of work from Singh and company is the next step in MRI motion correction. Not only is it excellent research work, but I believe these methods will be used in all kinds of clinical cases: children and older folks who can't sit still in the scanner, pathologies which induce motion, studies of moving tissue, even healthy patients will move in the magnet,” says Daniel Moyer, an assistant professor at Vanderbilt University. “In the future, I think that it likely will be standard practice to process images with something directly descended from this research.”\nCo-authors of this paper include Nalini Singh, Neel Dey, Malte Hoffmann, Bruce Fischl, Elfar Adalsteinsson, Robert Frost, Adrian Dalca and Polina Golland. This research was supported in part by GE Healthcare and by computational hardware provided by the Massachusetts Life Sciences Center. The research team thanks Steve Cauley for helpful discussions. Additional support was provided by NIH NIBIB, NIA, NIMH, NINDS, the Blueprint for Neuroscience Research, part of the multi-institutional Human Connectome Project, the BRAIN Initiative Cell Census Network, and a Google PhD Fellowship.\n",
    "published": "2023-08-17",
    "timestamp": "2023-08-24T13:21:21.396932"
  },
  {
    "unique_id": "f7031fbd-8590-5c68-afd9-01cb58e953c0",
    "title": "MIT researchers combine deep learning and physics to fix motion-corrupted MRI scans",
    "description": "The challenge involves more than just a blurry JPEG. Fixing motion artifacts in medical imaging requires a more sophisticated approach.",
    "link": "https://news.mit.edu/2023/mit-researchers-combine-deep-learning-physics-fix-motion-corrupted-MRI-scans-0817",
    "blog_text": "Compared to other imaging modalities like X-rays or CT scans, MRI scans provide high-quality soft tissue contrast. Unfortunately, MRI is highly sensitive to motion, with even the smallest of movements resulting in image artifacts. These artifacts put patients at risk of misdiagnoses or inappropriate treatment when critical details are obscured from the physician. But researchers at MIT may have developed a deep learning model capable of motion correction in brain MRI.\n“Motion is a common problem in MRI,” explains Nalini Singh, an Abdul Latif Jameel Clinic for Machine Learning in Health (Jameel Clinic)-affiliated PhD student in the Harvard-MIT Program in Health Sciences and Technology (HST) and lead author of the paper. “It’s a pretty slow imaging modality.”\nMRI sessions can take anywhere from a few minutes to an hour, depending on the type of images required. Even during the shortest scans, small movements can have dramatic effects on the resulting image. Unlike camera imaging, where motion typically manifests as a localized blur, motion in MRI often results in artifacts that can corrupt the whole image. Patients may be anesthetized or requested to limit deep breathing in order to minimize motion. However, these measures often cannot be taken in populations particularly susceptible to motion, including children and patients with psychiatric disorders. \nThe paper, titled “Data Consistent Deep Rigid MRI Motion Correction,” was recently awarded best oral presentation at the Medical Imaging with Deep Learning conference (MIDL) in Nashville, Tennessee. The method computationally constructs a motion-free image from motion-corrupted data without changing anything about the scanning procedure. “Our aim was to combine physics-based modeling and deep learning to get the best of both worlds,” Singh says.\nThe importance of this combined approach lies within ensuring consistency between the image output and the actual measurements of what is being depicted, otherwise the model creates “hallucinations” — images that appear realistic, but are physically and spatially inaccurate, potentially worsening outcomes when it comes to diagnoses.\nProcuring an MRI free of motion artifacts, particularly from patients with neurological disorders that cause involuntary movement, such as Alzheimer’s or Parkinson’s disease, would benefit more than just patient outcomes. A study from the University of Washington Department of Radiology estimated that motion affects 15 percent of brain MRIs. Motion in all types of MRI that leads to repeated scans or imaging sessions to obtain images with sufficient quality for diagnosis results in approximately $115,000 in hospital expenditures per scanner on an annual basis.\nAccording to Singh, future work could explore more sophisticated types of head motion as well as motion in other body parts. For instance, fetal MRI suffers from rapid, unpredictable motion that cannot be modeled only by simple translations and rotations. \n“This line of work from Singh and company is the next step in MRI motion correction. Not only is it excellent research work, but I believe these methods will be used in all kinds of clinical cases: children and older folks who can't sit still in the scanner, pathologies which induce motion, studies of moving tissue, even healthy patients will move in the magnet,” says Daniel Moyer, an assistant professor at Vanderbilt University. “In the future, I think that it likely will be standard practice to process images with something directly descended from this research.”\nCo-authors of this paper include Nalini Singh, Neel Dey, Malte Hoffmann, Bruce Fischl, Elfar Adalsteinsson, Robert Frost, Adrian Dalca and Polina Golland. This research was supported in part by GE Healthcare and by computational hardware provided by the Massachusetts Life Sciences Center. The research team thanks Steve Cauley for helpful discussions. Additional support was provided by NIH NIBIB, NIA, NIMH, NINDS, the Blueprint for Neuroscience Research, part of the multi-institutional Human Connectome Project, the BRAIN Initiative Cell Census Network, and a Google PhD Fellowship.\n",
    "published": "2023-08-17",
    "timestamp": "2023-08-31T13:41:01.213920"
  },
  {
    "unique_id": "e871e154-b34a-5c49-85aa-88729729054f",
    "title": "AI models are powerful, but are they biologically plausible?",
    "description": "A new study bridging neuroscience and machine learning offers insights into the potential role of astrocytes in the human brain.",
    "link": "https://news.mit.edu/2023/ai-models-astrocytes-role-brain-0815",
    "blog_text": "Artificial neural networks, ubiquitous machine-learning models that can be trained to complete many tasks, are so called because their architecture is inspired by the way biological neurons process information in the human brain.\nAbout six years ago, scientists discovered a new type of more powerful neural network model known as a transformer. These models can achieve unprecedented performance, such as by generating text from prompts with near-human-like accuracy. A transformer underlies AI systems such as ChatGPT and Bard, for example. While incredibly effective, transformers are also mysterious: Unlike with other brain-inspired neural network models, it hasn’t been clear how to build them using biological components.\nNow, researchers from MIT, the MIT-IBM Watson AI Lab, and Harvard Medical School have produced a hypothesis that may explain how a transformer could be built using biological elements in the brain. They suggest that a biological network composed of neurons and other brain cells called astrocytes could perform the same core computation as a transformer.\nRecent research has shown that astrocytes, non-neuronal cells that are abundant in the brain, communicate with neurons and play a role in some physiological processes, like regulating blood flow. But scientists still lack a clear understanding of what these cells do computationally.\nWith the new study, published this week in open-access format in the Proceedings of the National Academy of Sciences, the researchers explored the role astrocytes play in the brain from a computational perspective, and crafted a mathematical model that shows how they could be used, along with neurons, to build a biologically plausible transformer.\nTheir hypothesis provides insights that could spark future neuroscience research into how the human brain works. At the same time, it could help machine-learning researchers explain why transformers are so successful across a diverse set of complex tasks.\n“The brain is far superior to even the best artificial neural networks that we have developed, but we don’t really know exactly how the brain works. There is scientific value in thinking about connections between biological hardware and large-scale artificial intelligence networks. This is neuroscience for AI and AI for neuroscience,” says Dmitry Krotov, a research staff member at the MIT-IBM Watson AI Lab and senior author of the research paper.\nJoining Krotov on the paper are lead author Leo Kozachkov, a postdoc in the MIT Department of Brain and Cognitive Sciences; and Ksenia V. Kastanenka, an assistant professor of neurobiology at Harvard Medical School and an assistant investigator at the Massachusetts General Research Institute.  \nA biological impossibility becomes plausible\nTransformers operate differently than other neural network models. For instance, a recurrent neural network trained for natural language processing would compare each word in a sentence to an internal state determined by the previous words. A transformer, on the other hand, compares all the words in the sentence at once to generate a prediction, a process called self-attention.\nFor self-attention to work, the transformer must keep all the words ready in some form of memory, Krotov explains, but this didn’t seem biologically possible due to the way neurons communicate.\nHowever, a few years ago scientists studying a slightly different type of machine-learning model (known as a Dense Associated Memory) realized that this self-attention mechanism could occur in the brain, but only if there were communication between at least three neurons.\n“The number three really popped out to me because it is known in neuroscience that these cells called astrocytes, which are not neurons, form three-way connections with neurons, what are called tripartite synapses,” Kozachkov says.\nWhen two neurons communicate, a presynaptic neuron sends chemicals called neurotransmitters across the synapse that connects it to a postsynaptic neuron. Sometimes, an astrocyte is also connected — it wraps a long, thin tentacle around the synapse, creating a tripartite (three-part) synapse. One astrocyte may form millions of tripartite synapses.\nThe astrocyte collects some neurotransmitters that flow through the synaptic junction. At some point, the astrocyte can signal back to the neurons. Because astrocytes operate on a much longer time scale than neurons — they create signals by slowly elevating their calcium response and then decreasing it — these cells can hold and integrate information communicated to them from neurons. In this way, astrocytes can form a type of memory buffer, Krotov says.\n“If you think about it from that perspective, then astrocytes are extremely natural for precisely the computation we need to perform the attention operation inside transformers,” he adds.\nBuilding a neuron-astrocyte network\nWith this insight, the researchers formed their hypothesis that astrocytes could play a role in how transformers compute. Then they set out to build a mathematical model of a neuron-astrocyte network that would operate like a transformer.\nThey took the core mathematics that comprise a transformer and developed simple biophysical models of what astrocytes and neurons do when they communicate in the brain, based on a deep dive into the literature and guidance from neuroscientist collaborators.\nThen they combined the models in certain ways until they arrived at an equation of a neuron-astrocyte network that describes a transformer’s self-attention.\n“Sometimes, we found that certain things we wanted to be true couldn’t be plausibly implemented. So, we had to think of workarounds. There are some things in the paper that are very careful approximations of the transformer architecture to be able to match it in a biologically plausible way,” Kozachkov says.\nThrough their analysis, the researchers showed that their biophysical neuron-astrocyte network theoretically matches a transformer. In addition, they conducted numerical simulations by feeding images and paragraphs of text to transformer models and comparing the responses to those of their simulated neuron-astrocyte network. Both responded to the prompts in similar ways, confirming their theoretical model.\n“Having remained electrically silent for over a century of brain recordings, astrocytes are one of the most abundant, yet less explored, cells in the brain. The potential of unleashing the computational power of the other half of our brain is enormous,” says Konstantinos Michmizos, associate professor of computer science at Rutgers University, who was not involved with this work. “This study opens up a fascinating iterative loop, from understanding how intelligent behavior may truly emerge in the brain, to translating disruptive hypotheses into new tools that exhibit human-like intelligence.”\nThe next step for the researchers is to make the leap from theory to practice. They hope to compare the model’s predictions to those that have been observed in biological experiments, and use this knowledge to refine, or possibly disprove, their hypothesis.\nIn addition, one implication of their study is that astrocytes may be involved in long-term memory, since the network needs to store information to be able act on it in the future. Additional research could investigate this idea further, Krotov says.\n“For a lot of reasons, astrocytes are extremely important for cognition and behavior, and they operate in fundamentally different ways from neurons. My biggest hope for this paper is that it catalyzes a bunch of research in computational neuroscience toward glial cells, and in particular, astrocytes,” adds Kozachkov.\nThis research was supported, in part, by the BrightFocus Foundation and the National Institute of Health.\n",
    "published": "2023-08-15",
    "timestamp": "2023-08-24T13:21:21.398657"
  },
  {
    "unique_id": "e871e154-b34a-5c49-85aa-88729729054f",
    "title": "AI models are powerful, but are they biologically plausible?",
    "description": "A new study bridging neuroscience and machine learning offers insights into the potential role of astrocytes in the human brain.",
    "link": "https://news.mit.edu/2023/ai-models-astrocytes-role-brain-0815",
    "blog_text": "Artificial neural networks, ubiquitous machine-learning models that can be trained to complete many tasks, are so called because their architecture is inspired by the way biological neurons process information in the human brain.\nAbout six years ago, scientists discovered a new type of more powerful neural network model known as a transformer. These models can achieve unprecedented performance, such as by generating text from prompts with near-human-like accuracy. A transformer underlies AI systems such as ChatGPT and Bard, for example. While incredibly effective, transformers are also mysterious: Unlike with other brain-inspired neural network models, it hasn’t been clear how to build them using biological components.\nNow, researchers from MIT, the MIT-IBM Watson AI Lab, and Harvard Medical School have produced a hypothesis that may explain how a transformer could be built using biological elements in the brain. They suggest that a biological network composed of neurons and other brain cells called astrocytes could perform the same core computation as a transformer.\nRecent research has shown that astrocytes, non-neuronal cells that are abundant in the brain, communicate with neurons and play a role in some physiological processes, like regulating blood flow. But scientists still lack a clear understanding of what these cells do computationally.\nWith the new study, published this week in open-access format in the Proceedings of the National Academy of Sciences, the researchers explored the role astrocytes play in the brain from a computational perspective, and crafted a mathematical model that shows how they could be used, along with neurons, to build a biologically plausible transformer.\nTheir hypothesis provides insights that could spark future neuroscience research into how the human brain works. At the same time, it could help machine-learning researchers explain why transformers are so successful across a diverse set of complex tasks.\n“The brain is far superior to even the best artificial neural networks that we have developed, but we don’t really know exactly how the brain works. There is scientific value in thinking about connections between biological hardware and large-scale artificial intelligence networks. This is neuroscience for AI and AI for neuroscience,” says Dmitry Krotov, a research staff member at the MIT-IBM Watson AI Lab and senior author of the research paper.\nJoining Krotov on the paper are lead author Leo Kozachkov, a postdoc in the MIT Department of Brain and Cognitive Sciences; and Ksenia V. Kastanenka, an assistant professor of neurobiology at Harvard Medical School and an assistant investigator at the Massachusetts General Research Institute.  \nA biological impossibility becomes plausible\nTransformers operate differently than other neural network models. For instance, a recurrent neural network trained for natural language processing would compare each word in a sentence to an internal state determined by the previous words. A transformer, on the other hand, compares all the words in the sentence at once to generate a prediction, a process called self-attention.\nFor self-attention to work, the transformer must keep all the words ready in some form of memory, Krotov explains, but this didn’t seem biologically possible due to the way neurons communicate.\nHowever, a few years ago scientists studying a slightly different type of machine-learning model (known as a Dense Associated Memory) realized that this self-attention mechanism could occur in the brain, but only if there were communication between at least three neurons.\n“The number three really popped out to me because it is known in neuroscience that these cells called astrocytes, which are not neurons, form three-way connections with neurons, what are called tripartite synapses,” Kozachkov says.\nWhen two neurons communicate, a presynaptic neuron sends chemicals called neurotransmitters across the synapse that connects it to a postsynaptic neuron. Sometimes, an astrocyte is also connected — it wraps a long, thin tentacle around the synapse, creating a tripartite (three-part) synapse. One astrocyte may form millions of tripartite synapses.\nThe astrocyte collects some neurotransmitters that flow through the synaptic junction. At some point, the astrocyte can signal back to the neurons. Because astrocytes operate on a much longer time scale than neurons — they create signals by slowly elevating their calcium response and then decreasing it — these cells can hold and integrate information communicated to them from neurons. In this way, astrocytes can form a type of memory buffer, Krotov says.\n“If you think about it from that perspective, then astrocytes are extremely natural for precisely the computation we need to perform the attention operation inside transformers,” he adds.\nBuilding a neuron-astrocyte network\nWith this insight, the researchers formed their hypothesis that astrocytes could play a role in how transformers compute. Then they set out to build a mathematical model of a neuron-astrocyte network that would operate like a transformer.\nThey took the core mathematics that comprise a transformer and developed simple biophysical models of what astrocytes and neurons do when they communicate in the brain, based on a deep dive into the literature and guidance from neuroscientist collaborators.\nThen they combined the models in certain ways until they arrived at an equation of a neuron-astrocyte network that describes a transformer’s self-attention.\n“Sometimes, we found that certain things we wanted to be true couldn’t be plausibly implemented. So, we had to think of workarounds. There are some things in the paper that are very careful approximations of the transformer architecture to be able to match it in a biologically plausible way,” Kozachkov says.\nThrough their analysis, the researchers showed that their biophysical neuron-astrocyte network theoretically matches a transformer. In addition, they conducted numerical simulations by feeding images and paragraphs of text to transformer models and comparing the responses to those of their simulated neuron-astrocyte network. Both responded to the prompts in similar ways, confirming their theoretical model.\n“Having remained electrically silent for over a century of brain recordings, astrocytes are one of the most abundant, yet less explored, cells in the brain. The potential of unleashing the computational power of the other half of our brain is enormous,” says Konstantinos Michmizos, associate professor of computer science at Rutgers University, who was not involved with this work. “This study opens up a fascinating iterative loop, from understanding how intelligent behavior may truly emerge in the brain, to translating disruptive hypotheses into new tools that exhibit human-like intelligence.”\nThe next step for the researchers is to make the leap from theory to practice. They hope to compare the model’s predictions to those that have been observed in biological experiments, and use this knowledge to refine, or possibly disprove, their hypothesis.\nIn addition, one implication of their study is that astrocytes may be involved in long-term memory, since the network needs to store information to be able act on it in the future. Additional research could investigate this idea further, Krotov says.\n“For a lot of reasons, astrocytes are extremely important for cognition and behavior, and they operate in fundamentally different ways from neurons. My biggest hope for this paper is that it catalyzes a bunch of research in computational neuroscience toward glial cells, and in particular, astrocytes,” adds Kozachkov.\nThis research was supported, in part, by the BrightFocus Foundation and the National Institute of Health.\n",
    "published": "2023-08-15",
    "timestamp": "2023-08-28T13:36:51.689339"
  }
];